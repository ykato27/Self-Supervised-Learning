{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykato27/Self-Supervised-Learning/blob/main/Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XzxTZfKwFNo"
      },
      "source": [
        "# Feature Extraction\n",
        "\n",
        "In this tutorial, we look at a simple example of how to use VISSL to extract features for [ResNet-50 Torchvision pre-trained model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16).\n",
        "\n",
        "You can make a copy of this tutorial by `File -> Open in playground mode` and make changes there. DO NOT request access to this tutorial.\n",
        "\n",
        "**NOTE:** Please ensure your Collab Notebook has GPU available. To ensure/select this, simple follow: `Edit -> Notebook Settings -> select GPU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohdWhBSw69e"
      },
      "source": [
        "## Install VISSL\n",
        "\n",
        "Installing VISSL is pretty straightfoward. We will use pip binaries of VISSL and follow instructions from [here](https://github.com/facebookresearch/vissl/blob/master/INSTALL.md#install-vissl-pip-package)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5ISg59KTOqU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f7d24bb-8ec9-41ae-c7af-9d52de691ec8"
      },
      "source": [
        "# Install: PyTorch (VISSL works with all PyTorch versions >=1.4)\n",
        "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
        "!pip install torchtext==0.9.1\n",
        "\n",
        "# install opencv\n",
        "!pip install opencv-python\n",
        "\n",
        "# install apex by checking system settings: cuda version, pytorch version, python version\n",
        "import sys\n",
        "import torch\n",
        "version_str=\"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\",\"\"),\n",
        "    f\"_pyt{torch.__version__[0:5:2]}\"\n",
        "])\n",
        "print(version_str)\n",
        "\n",
        "# install apex (pre-compiled with optimizer C++ extensions and CUDA kernels)\n",
        "!pip install apex -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/{version_str}/download.html\n",
        "\n",
        "# install VISSL\n",
        "!pip install vissl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
            "Collecting torch==1.8.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/lts/1.8/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1 MB 32.5 MB/s eta 0:00:36tcmalloc: large alloc 1147494400 bytes == 0x5575460e8000 @  0x7f53fb8a0615 0x55754406e4cc 0x55754414e47a 0x5575440712ed 0x557544162e1d 0x5575440e4e99 0x5575440df9ee 0x557544072bda 0x5575440e4d00 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x557544163c66 0x5575440e0daf 0x557544163c66 0x5575440e0daf 0x557544163c66 0x5575440e0daf 0x557544073039 0x5575440b6409 0x557544071c52 0x5575440e4c25 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x5575440df9ee 0x557544072bda 0x5575440e0915 0x557544072afa 0x5575440e0c0d 0x5575440df9ee\n",
            "\u001b[K     |█████████████████               | 1055.7 MB 1.6 MB/s eta 0:09:46tcmalloc: large alloc 1434370048 bytes == 0x55758a73e000 @  0x7f53fb8a0615 0x55754406e4cc 0x55754414e47a 0x5575440712ed 0x557544162e1d 0x5575440e4e99 0x5575440df9ee 0x557544072bda 0x5575440e4d00 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x557544163c66 0x5575440e0daf 0x557544163c66 0x5575440e0daf 0x557544163c66 0x5575440e0daf 0x557544073039 0x5575440b6409 0x557544071c52 0x5575440e4c25 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x5575440df9ee 0x557544072bda 0x5575440e0915 0x557544072afa 0x5575440e0c0d 0x5575440df9ee\n",
            "\u001b[K     |█████████████████████▋          | 1336.2 MB 47.4 MB/s eta 0:00:14tcmalloc: large alloc 1792966656 bytes == 0x5575dff2a000 @  0x7f53fb8a0615 0x55754406e4cc 0x55754414e47a 0x5575440712ed 0x557544162e1d 0x5575440e4e99 0x5575440df9ee 0x557544072bda 0x5575440e4d00 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x557544163c66 0x5575440e0daf 0x557544163c66 0x5575440e0daf 0x557544163c66 0x5575440e0daf 0x557544073039 0x5575440b6409 0x557544071c52 0x5575440e4c25 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x5575440df9ee 0x557544072bda 0x5575440e0915 0x557544072afa 0x5575440e0c0d 0x5575440df9ee\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.5 MB/s eta 0:03:16tcmalloc: large alloc 2241208320 bytes == 0x5575460e8000 @  0x7f53fb8a0615 0x55754406e4cc 0x55754414e47a 0x5575440712ed 0x557544162e1d 0x5575440e4e99 0x5575440df9ee 0x557544072bda 0x5575440e4d00 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x557544163c66 0x5575440e0daf 0x557544163c66 0x5575440e0daf 0x557544163c66 0x5575440e0daf 0x557544073039 0x5575440b6409 0x557544071c52 0x5575440e4c25 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x5575440df9ee 0x557544072bda 0x5575440e0915 0x557544072afa 0x5575440e0c0d 0x5575440df9ee\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 1.6 MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0x5575cba4a000 @  0x7f53fb89f1e7 0x5575440a4067 0x55754406e4cc 0x55754414e47a 0x5575440712ed 0x557544162e1d 0x5575440e4e99 0x5575440df9ee 0x557544072bda 0x5575440e0c0d 0x5575440df9ee 0x557544072bda 0x5575440e0c0d 0x5575440df9ee 0x557544072bda 0x5575440e0c0d 0x5575440df9ee 0x557544072bda 0x5575440e0c0d 0x5575440df9ee 0x557544072bda 0x5575440e0c0d 0x557544072afa 0x5575440e0c0d 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x5575440df9ee\n",
            "tcmalloc: large alloc 2477727744 bytes == 0x557641ca4000 @  0x7f53fb8a0615 0x55754406e4cc 0x55754414e47a 0x5575440712ed 0x557544162e1d 0x5575440e4e99 0x5575440df9ee 0x557544072bda 0x5575440e0c0d 0x5575440df9ee 0x557544072bda 0x5575440e0c0d 0x5575440df9ee 0x557544072bda 0x5575440e0c0d 0x5575440df9ee 0x557544072bda 0x5575440e0c0d 0x5575440df9ee 0x557544072bda 0x5575440e0c0d 0x557544072afa 0x5575440e0c0d 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x5575440df9ee 0x557544072bda 0x5575440e1737 0x5575440df9ee 0x557544073271\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 1.4 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/lts/1.8/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6 MB 33.2 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.1\n",
            "  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "      Successfully uninstalled torch-1.9.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu111\n",
            "    Uninstalling torchvision-0.10.0+cu111:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.1+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111\n",
            "Collecting torchtext==0.9.1\n",
            "  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1) (2.23.0)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1) (1.8.1+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchtext==0.9.1) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (2021.5.30)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed torchtext-0.9.1\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "py37_cu111_pyt181\n",
            "Looking in links: https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/py37_cu111_pyt181/download.html\n",
            "Collecting apex\n",
            "  Downloading https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/py37_cu111_pyt181/apex-0.1-cp37-cp37m-linux_x86_64.whl (14.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1 MB 68 kB/s \n",
            "\u001b[?25hInstalling collected packages: apex\n",
            "Successfully installed apex-0.1\n",
            "Collecting vissl\n",
            "  Downloading vissl-0.1.5-py3-none-any.whl (754 kB)\n",
            "\u001b[K     |████████████████████████████████| 754 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting faiss>=1.5.3\n",
            "  Downloading faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 35.6 MB/s \n",
            "\u001b[?25hCollecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20211023.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from vissl) (0.22.2.post1)\n",
            "Collecting fairscale\n",
            "  Downloading fairscale-0.4.1.tar.gz (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 44.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from vissl) (2.0.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from vissl) (0.29.24)\n",
            "Collecting parameterized==0.7.4\n",
            "  Downloading parameterized-0.7.4-py2.py3-none-any.whl (25 kB)\n",
            "Collecting hydra-core>=1.0\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 46.1 MB/s \n",
            "\u001b[?25hCollecting tensorboard==1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 38.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from vissl) (0.8.9)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from vissl) (1.19.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (1.41.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (0.37.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (1.0.1)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 45.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0->vissl) (5.2.2)\n",
            "Collecting omegaconf==2.1.*\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 29.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard==1.15.0->vissl) (4.8.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.1->vissl) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (2.4.7)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from fairscale->vissl) (1.8.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->fairscale->vissl) (3.7.4.3)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->vissl) (4.62.3)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->vissl) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore->vissl) (7.1.2)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard==1.15.0->vissl) (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->vissl) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->vissl) (1.0.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, fairscale, fvcore\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=125cf9a4fdbdd87b756a88ef0b67ccc878d8138d4594c23122f1810278945575\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.1-py3-none-any.whl size=238993 sha256=aa451957ea64d6454dc642137eb9a41b2fcc839f54dfe52b01b6b54834d9f754\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/d7/c1/9e39a3a42e9d881913e4e6645ce2bc3653e5a45833fc22e2fd\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20211023-py3-none-any.whl size=60947 sha256=d982eed9a41aa54260fa8205e69d0c20fc9855cf39036c13a357a5fffb62e500\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/98/fc/252d62cab6263c719120e06b28f3378af59b52ce7a20e81852\n",
            "Successfully built antlr4-python3-runtime fairscale fvcore\n",
            "Installing collected packages: PyYAML, portalocker, antlr4-python3-runtime, yacs, omegaconf, iopath, tensorboard, parameterized, hydra-core, fvcore, faiss, fairscale, vissl\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.6.0\n",
            "    Uninstalling tensorboard-2.6.0:\n",
            "      Successfully uninstalled tensorboard-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires tensorboard~=2.6, but you have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 fairscale-0.4.1 faiss-1.5.3 fvcore-0.1.5.post20211023 hydra-core-1.1.1 iopath-0.1.9 omegaconf-2.1.1 parameterized-0.7.4 portalocker-2.3.2 tensorboard-1.15.0 vissl-0.1.5 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Fxe3MWxqsI"
      },
      "source": [
        "VISSL should be successfuly installed by now and all the dependencies should be available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np6atgoOTPrA"
      },
      "source": [
        "import vissl\n",
        "import tensorboard\n",
        "import apex\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFEHZ4KdxzWq"
      },
      "source": [
        "## YAML config file for Feature Extraction\n",
        "\n",
        "VISSL provides yaml configuration files for extracting features [here](https://github.com/facebookresearch/vissl/tree/master/configs/config/feature_extraction). \n",
        "\n",
        "For the purpose of this tutorial, we will use the config file for extracting features from several layers in the trunk of ResNet-50 supervised model on 1-gpu. Let's go ahead and download the [example config file](https://github.com/facebookresearch/vissl/blob/master/configs/config/feature_extraction/extract_resnet_in1k_8gpu.yaml) and [feature settings for trunk layers](https://github.com/facebookresearch/vissl/blob/master/configs/config/feature_extraction/trunk_only/rn50_layers.yaml).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ufyNAeUaDSs"
      },
      "source": [
        "!mkdir -p configs/config/trunk_only\n",
        "!wget -q -O configs/__init__.py https://dl.fbaipublicfiles.com/vissl/tutorials/configs/__init__.py \n",
        "!wget -q -O configs/config/extract_resnet_in1k_8gpu.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/extract_resnet_in1k_8gpu.yaml\n",
        "!wget -q -O configs/config/trunk_only/rn50_layers.yaml https://dl.fbaipublicfiles.com/vissl/tutorials/configs/trunk_only/rn50_layers.yaml"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMXLYLpsJXj"
      },
      "source": [
        "## Download the ResNet-50 weights from Torchvision\n",
        "\n",
        "We download the weights from the [torchvision ResNet50 model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv0quZwFsWxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0088bcc4-f961-4a26-e22f-64a6bd20ce5e"
      },
      "source": [
        "!wget https://download.pytorch.org/models/resnet50-19c8e357.pth"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-25 13:45:27--  https://download.pytorch.org/models/resnet50-19c8e357.pth\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.249.93.29, 13.249.93.14, 13.249.93.46, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.249.93.29|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102502400 (98M) [application/octet-stream]\n",
            "Saving to: ‘resnet50-19c8e357.pth’\n",
            "\n",
            "resnet50-19c8e357.p 100%[===================>]  97.75M  34.6MB/s    in 2.8s    \n",
            "\n",
            "2021-10-25 13:45:30 (34.6 MB/s) - ‘resnet50-19c8e357.pth’ saved [102502400/102502400]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndNMJGSRyffl"
      },
      "source": [
        "## Builtin feature extraction tool in VISSL\n",
        "\n",
        "VISSL also provides a [helper python tool](https://github.com/facebookresearch/vissl/blob/master/tools/run_distributed_engines.py) that allows to use VISSL for training purposes. This tool offers:\n",
        "- allows training and feature extraction both using VISSL. \n",
        "- also allows training on 1-gpu or multi-gpu. \n",
        "- can be used to launch multi-machine distributed training.\n",
        "\n",
        "Let's go ahead and download this tool directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6io7qQWzCbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113cbf65-aef0-4ec5-b54f-ba05ada2751e"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-25 13:45:30--  https://dl.fbaipublicfiles.com/vissl/tutorials/run_distributed_engines.py\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6568 (6.4K) [text/x-python]\n",
            "Saving to: ‘run_distributed_engines.py’\n",
            "\n",
            "run_distributed_eng 100%[===================>]   6.41K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-25 13:45:30 (58.6 MB/s) - ‘run_distributed_engines.py’ saved [6568/6568]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0hng2EPY7pr"
      },
      "source": [
        "## Creating a custom data\n",
        "\n",
        "For the purpose of this tutorial, since we don't have ImageNet on the disk, we will create a dummy dataset by copying an image from COCO dataset in ImageNet dataset folder style as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-sy6nD-RfwB"
      },
      "source": [
        "!mkdir -p dummy_data/train/class1\n",
        "!mkdir -p dummy_data/train/class2\n",
        "!mkdir -p dummy_data/val/class1\n",
        "!mkdir -p dummy_data/val/class2\n",
        "\n",
        "# create 2 classes in train and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/train/class2/img5.jpg\n",
        "\n",
        "# create 2 classes in val and add 5 images per class\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class1/img5.jpg\n",
        "\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img1.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img2.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img3.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img4.jpg\n",
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O dummy_data/val/class2/img5.jpg\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPGCiTsXZeW3"
      },
      "source": [
        "## Using the custom data in VISSL\n",
        "\n",
        "Next step for us is to register the dummy data we created above with VISSL. Registering the dataset involves telling VISSL about the dataset name and the paths for the dataset. For this, we create a simple json file with the metadata and save it to `configs/config/dataset_catalog.py` file.\n",
        "\n",
        "**NOTE**: VISSL uses the specific `dataset_catalog.json` under the path `configs/config/dataset_catalog.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Q6LCqaWjl1"
      },
      "source": [
        "json_data = {\n",
        "    \"dummy_data_folder\": {\n",
        "      \"train\": [\n",
        "        \"/content/dummy_data/train\", \"/content/dummy_data/train\"\n",
        "      ],\n",
        "      \"val\": [\n",
        "        \"/content/dummy_data/val\", \"/content/dummy_data/val\"\n",
        "      ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# use VISSL's api to save or you can use your custom code.\n",
        "from vissl.utils.io import save_file\n",
        "save_file(json_data, \"/content/configs/config/dataset_catalog.json\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otN1pB32cBHK"
      },
      "source": [
        "Next, we verify that the dataset is registered with VISSL. For that we query VISSL's dataset catalog as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZBhH-s5bcHd",
        "outputId": "c0f14ba7-ba52-4181-e1fb-0e549c2b7fdd"
      },
      "source": [
        "from vissl.data.dataset_catalog import VisslDatasetCatalog\n",
        "\n",
        "# list all the datasets that exist in catalog\n",
        "print(VisslDatasetCatalog.list())\n",
        "\n",
        "# get the metadata of dummy_data_folder dataset\n",
        "print(VisslDatasetCatalog.get(\"dummy_data_folder\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dummy_data_folder']\n",
            "{'train': ['/content/dummy_data/train', '/content/dummy_data/train'], 'val': ['/content/dummy_data/val', '/content/dummy_data/val']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaUMDwMdzYHN"
      },
      "source": [
        "## Extract the features\n",
        "\n",
        "We are ready to extract features now. For the purpose of this tutorial, we will use synthetic dataset and train on dummy images. VISSL supports training on wide range of datasets and allows adding custom datasets. Please see VISSL documentation on how to use the datasets. To train on ImageNet instead: assuming your ImageNet dataset folder path is `/path/to/my/imagenet/folder/`, you can add the following command line \n",
        "input to your training command: \n",
        "```\n",
        "config.DATA.TRAIN.DATASET_NAMES=[imagenet1k_folder] \\\n",
        "config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "config.DATA.TRAIN.DATA_PATHS=[\"/path/to/my/imagenet/folder/train\"] \\\n",
        "config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM7IigSpONW0"
      },
      "source": [
        "The feature extraction command looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v0HvauIj9S2",
        "outputId": "085455ff-c0e6-4ef9-bbbd-7dae793c7a6b"
      },
      "source": [
        "!python3 run_distributed_engines.py \\\n",
        "    hydra.verbose=true \\\n",
        "    config=extract_resnet_in1k_8gpu \\\n",
        "    +config/trunk_only=rn50_layers \\\n",
        "    config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DATA.TEST.DATA_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.LABEL_SOURCES=[disk_folder] \\\n",
        "    config.DATA.TEST.DATASET_NAMES=[dummy_data_folder] \\\n",
        "    config.DATA.TEST.BATCHSIZE_PER_REPLICA=2 \\\n",
        "    config.DISTRIBUTED.NUM_NODES=1 \\\n",
        "    config.DISTRIBUTED.NUM_PROC_PER_NODE=1 \\\n",
        "    config.CHECKPOINT.DIR=\"./checkpoints\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=\"/content/resnet50-19c8e357.pth\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=\"trunk.base_model._feature_blocks.\" \\\n",
        "    config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=\"\"\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####### overrides: ['hydra.verbose=true', 'config=extract_resnet_in1k_8gpu', '+config/trunk_only=rn50_layers', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=./checkpoints', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk.base_model._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'hydra.verbose=true']\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/experimental/initialize.py:68: UserWarning: hydra.experimental.initialize_config_module() is no longer experimental. Use hydra.initialize_config_module().\n",
            "  message=\"hydra.experimental.initialize_config_module() is no longer experimental.\"\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/experimental/compose.py:19: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
            "  message=\"hydra.experimental.compose() is no longer experimental.\"\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'defaults': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
            "  warnings.warn(msg, UserWarning)\n",
            "INFO 2021-10-25 13:45:40,961 __init__.py:  32: Provided Config has latest version: 1\n",
            "INFO 2021-10-25 13:45:40,962 run_distributed_engines.py: 163: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:54433\n",
            "INFO 2021-10-25 13:45:40,962 train.py:  66: Env set for rank: 0, dist_rank: 0\n",
            "INFO 2021-10-25 13:45:40,963 env.py:  41: CLICOLOR:\t1\n",
            "INFO 2021-10-25 13:45:40,963 env.py:  41: CLOUDSDK_CONFIG:\t/content/.config\n",
            "INFO 2021-10-25 13:45:40,963 env.py:  41: CLOUDSDK_PYTHON:\tpython3\n",
            "INFO 2021-10-25 13:45:40,963 env.py:  41: COLAB_GPU:\t1\n",
            "INFO 2021-10-25 13:45:40,963 env.py:  41: CUDA_VERSION:\t11.1.1\n",
            "INFO 2021-10-25 13:45:40,963 env.py:  41: CUDNN_VERSION:\t8.0.5.39\n",
            "INFO 2021-10-25 13:45:40,963 env.py:  41: DATALAB_SETTINGS_OVERRIDES:\t{\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"],\"debugAdapterMultiplexerPath\":\"/usr/local/bin/dap_multiplexer\",\"enableLsp\":true}\n",
            "INFO 2021-10-25 13:45:40,964 env.py:  41: DEBIAN_FRONTEND:\tnoninteractive\n",
            "INFO 2021-10-25 13:45:40,964 env.py:  41: ENV:\t/root/.bashrc\n",
            "INFO 2021-10-25 13:45:40,964 env.py:  41: GCE_METADATA_TIMEOUT:\t0\n",
            "INFO 2021-10-25 13:45:40,964 env.py:  41: GCS_READ_CACHE_BLOCK_SIZE_MB:\t16\n",
            "INFO 2021-10-25 13:45:40,964 env.py:  41: GIT_PAGER:\tcat\n",
            "INFO 2021-10-25 13:45:40,964 env.py:  41: GLIBCPP_FORCE_NEW:\t1\n",
            "INFO 2021-10-25 13:45:40,964 env.py:  41: GLIBCXX_FORCE_NEW:\t1\n",
            "INFO 2021-10-25 13:45:40,964 env.py:  41: HOME:\t/root\n",
            "INFO 2021-10-25 13:45:40,965 env.py:  41: HOSTNAME:\t6ad74319c91f\n",
            "INFO 2021-10-25 13:45:40,965 env.py:  41: JPY_PARENT_PID:\t66\n",
            "INFO 2021-10-25 13:45:40,965 env.py:  41: LANG:\ten_US.UTF-8\n",
            "INFO 2021-10-25 13:45:40,965 env.py:  41: LAST_FORCED_REBUILD:\t20211007\n",
            "INFO 2021-10-25 13:45:40,965 env.py:  41: LD_LIBRARY_PATH:\t/usr/lib64-nvidia\n",
            "INFO 2021-10-25 13:45:40,965 env.py:  41: LD_PRELOAD:\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n",
            "INFO 2021-10-25 13:45:40,966 env.py:  41: LIBRARY_PATH:\t/usr/local/cuda/lib64/stubs\n",
            "INFO 2021-10-25 13:45:40,966 env.py:  41: LOCAL_RANK:\t0\n",
            "INFO 2021-10-25 13:45:40,966 env.py:  41: MPLBACKEND:\tmodule://ipykernel.pylab.backend_inline\n",
            "INFO 2021-10-25 13:45:40,966 env.py:  41: NCCL_VERSION:\t2.7.8\n",
            "INFO 2021-10-25 13:45:40,966 env.py:  41: NO_GCE_CHECK:\tTrue\n",
            "INFO 2021-10-25 13:45:40,966 env.py:  41: NVIDIA_DRIVER_CAPABILITIES:\tcompute,utility\n",
            "INFO 2021-10-25 13:45:40,966 env.py:  41: NVIDIA_REQUIRE_CUDA:\tcuda>=11.1 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 brand=tesla,driver>=450,driver<451\n",
            "INFO 2021-10-25 13:45:40,967 env.py:  41: NVIDIA_VISIBLE_DEVICES:\tall\n",
            "INFO 2021-10-25 13:45:40,967 env.py:  41: OLDPWD:\t/\n",
            "INFO 2021-10-25 13:45:40,967 env.py:  41: PAGER:\tcat\n",
            "INFO 2021-10-25 13:45:40,967 env.py:  41: PATH:\t/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n",
            "INFO 2021-10-25 13:45:40,967 env.py:  41: PWD:\t/content\n",
            "INFO 2021-10-25 13:45:40,967 env.py:  41: PYDEVD_USE_FRAME_EVAL:\tNO\n",
            "INFO 2021-10-25 13:45:40,967 env.py:  41: PYTHONPATH:\t/env/python\n",
            "INFO 2021-10-25 13:45:40,968 env.py:  41: PYTHONWARNINGS:\tignore:::pip._internal.cli.base_command\n",
            "INFO 2021-10-25 13:45:40,968 env.py:  41: RANK:\t0\n",
            "INFO 2021-10-25 13:45:40,968 env.py:  41: SHELL:\t/bin/bash\n",
            "INFO 2021-10-25 13:45:40,968 env.py:  41: SHLVL:\t1\n",
            "INFO 2021-10-25 13:45:40,968 env.py:  41: TBE_CREDS_ADDR:\t172.28.0.1:8008\n",
            "INFO 2021-10-25 13:45:40,968 env.py:  41: TERM:\txterm-color\n",
            "INFO 2021-10-25 13:45:40,968 env.py:  41: TF_FORCE_GPU_ALLOW_GROWTH:\ttrue\n",
            "INFO 2021-10-25 13:45:40,969 env.py:  41: WORLD_SIZE:\t1\n",
            "INFO 2021-10-25 13:45:40,969 env.py:  41: _:\t/usr/bin/python3\n",
            "INFO 2021-10-25 13:45:40,969 env.py:  41: __EGL_VENDOR_LIBRARY_DIRS:\t/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/\n",
            "INFO 2021-10-25 13:45:40,969 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-25 13:45:40,969 train.py:  77: Setting seed....\n",
            "INFO 2021-10-25 13:45:40,969 misc.py:  99: MACHINE SEED: 0\n",
            "INFO 2021-10-25 13:45:41,048 hydra_config.py: 140: Training with config:\n",
            "INFO 2021-10-25 13:45:41,055 hydra_config.py: 144: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,\n",
            "                'AUTO_RESUME': True,\n",
            "                'BACKEND': 'disk',\n",
            "                'CHECKPOINT_FREQUENCY': 1,\n",
            "                'CHECKPOINT_ITER_FREQUENCY': -1,\n",
            "                'DIR': './checkpoints',\n",
            "                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,\n",
            "                'OVERWRITE_EXISTING': False,\n",
            "                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},\n",
            " 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',\n",
            "                'FEATURES': {'DATASET_NAME': '',\n",
            "                             'DATA_PARTITION': 'TRAIN',\n",
            "                             'LAYER_NAME': ''},\n",
            "                'NUM_CLUSTERS': 16000,\n",
            "                'N_ITER': 50},\n",
            " 'DATA': {'DDP_BUCKET_CAP_MB': 25,\n",
            "          'ENABLE_ASYNC_GPU_COPY': True,\n",
            "          'NUM_DATALOADER_WORKERS': 4,\n",
            "          'PIN_MEMORY': True,\n",
            "          'TEST': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                   'COLLATE_FUNCTION': 'default_collate',\n",
            "                   'COLLATE_FUNCTION_PARAMS': {},\n",
            "                   'COPY_DESTINATION_DIR': '',\n",
            "                   'COPY_TO_LOCAL_DISK': False,\n",
            "                   'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                   'DATA_LIMIT': -1,\n",
            "                   'DATA_PATHS': [],\n",
            "                   'DATA_SOURCES': ['disk_folder'],\n",
            "                   'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                   'DROP_LAST': False,\n",
            "                   'ENABLE_QUEUE_DATASET': False,\n",
            "                   'INPUT_KEY_NAMES': ['data'],\n",
            "                   'LABEL_PATHS': [],\n",
            "                   'LABEL_SOURCES': ['disk_folder'],\n",
            "                   'LABEL_TYPE': 'standard',\n",
            "                   'MMAP_MODE': True,\n",
            "                   'TARGET_KEY_NAMES': ['label'],\n",
            "                   'TRANSFORMS': [],\n",
            "                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},\n",
            "          'TRAIN': {'BATCHSIZE_PER_REPLICA': 2,\n",
            "                    'COLLATE_FUNCTION': 'default_collate',\n",
            "                    'COLLATE_FUNCTION_PARAMS': {},\n",
            "                    'COPY_DESTINATION_DIR': '',\n",
            "                    'COPY_TO_LOCAL_DISK': False,\n",
            "                    'DATASET_NAMES': ['dummy_data_folder'],\n",
            "                    'DATA_LIMIT': -1,\n",
            "                    'DATA_PATHS': [],\n",
            "                    'DATA_SOURCES': ['disk_folder'],\n",
            "                    'DEFAULT_GRAY_IMG_SIZE': 224,\n",
            "                    'DROP_LAST': False,\n",
            "                    'ENABLE_QUEUE_DATASET': False,\n",
            "                    'INPUT_KEY_NAMES': ['data'],\n",
            "                    'LABEL_PATHS': [],\n",
            "                    'LABEL_SOURCES': ['disk_folder'],\n",
            "                    'LABEL_TYPE': 'standard',\n",
            "                    'MMAP_MODE': True,\n",
            "                    'TARGET_KEY_NAMES': ['label'],\n",
            "                    'TRANSFORMS': [],\n",
            "                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},\n",
            " 'DISTRIBUTED': {'BACKEND': 'nccl',\n",
            "                 'BROADCAST_BUFFERS': True,\n",
            "                 'INIT_METHOD': 'tcp',\n",
            "                 'MANUAL_GRADIENT_REDUCTION': False,\n",
            "                 'NCCL_DEBUG': False,\n",
            "                 'NCCL_SOCKET_NTHREADS': '',\n",
            "                 'NUM_NODES': 1,\n",
            "                 'NUM_PROC_PER_NODE': 1,\n",
            "                 'RUN_ID': 'auto'},\n",
            " 'IMG_RETRIEVAL': {'DATASET_PATH': '',\n",
            "                   'EVAL_BINARY_PATH': '',\n",
            "                   'EVAL_DATASET_NAME': 'Paris',\n",
            "                   'FEATS_PROCESSING_TYPE': '',\n",
            "                   'GEM_POOL_POWER': 4.0,\n",
            "                   'N_PCA': 512,\n",
            "                   'RESIZE_IMG': 1024,\n",
            "                   'SHOULD_TRAIN_PCA_OR_WHITENING': True,\n",
            "                   'SPATIAL_LEVELS': 3,\n",
            "                   'TEMP_DIR': '/tmp/instance_retrieval/',\n",
            "                   'TRAIN_DATASET_NAME': 'Oxford',\n",
            "                   'WHITEN_IMG_LIST': ''},\n",
            " 'LOG_FREQUENCY': 10,\n",
            " 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},\n",
            "          'bce_logits_multiple_output_single_target': {'normalize_output': False,\n",
            "                                                       'reduction': 'none',\n",
            "                                                       'world_size': 1},\n",
            "          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,\n",
            "                                                          'normalize_output': False,\n",
            "                                                          'reduction': 'mean',\n",
            "                                                          'temperature': 1.0,\n",
            "                                                          'weight': None},\n",
            "          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,\n",
            "                                 'DROP_LAST': True,\n",
            "                                 'kmeans_iters': 10,\n",
            "                                 'memory_params': {'crops_for_mb': [0],\n",
            "                                                   'embedding_dim': 128},\n",
            "                                 'num_clusters': [3000, 3000, 3000],\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_train_samples': -1,\n",
            "                                 'temperature': 0.1},\n",
            "          'moco_loss': {'embedding_dim': 128,\n",
            "                        'momentum': 0.999,\n",
            "                        'queue_size': 65536,\n",
            "                        'temperature': 0.2},\n",
            "          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                               'embedding_dim': 128,\n",
            "                                                               'world_size': 64},\n",
            "                                             'num_crops': 2,\n",
            "                                             'temperature': 0.1},\n",
            "          'name': 'CrossEntropyLoss',\n",
            "          'nce_loss_with_memory': {'loss_type': 'nce',\n",
            "                                   'loss_weights': [1.0],\n",
            "                                   'memory_params': {'embedding_dim': 128,\n",
            "                                                     'memory_size': -1,\n",
            "                                                     'momentum': 0.5,\n",
            "                                                     'norm_init': True,\n",
            "                                                     'update_mem_on_forward': True},\n",
            "                                   'negative_sampling_params': {'num_negatives': 16000,\n",
            "                                                                'type': 'random'},\n",
            "                                   'norm_constant': -1,\n",
            "                                   'norm_embedding': True,\n",
            "                                   'num_train_samples': -1,\n",
            "                                   'temperature': 0.07,\n",
            "                                   'update_mem_with_emb_index': -100},\n",
            "          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,\n",
            "                                                     'embedding_dim': 128,\n",
            "                                                     'world_size': 64},\n",
            "                                   'temperature': 0.1},\n",
            "          'swav_loss': {'crops_for_assign': [0, 1],\n",
            "                        'embedding_dim': 128,\n",
            "                        'epsilon': 0.05,\n",
            "                        'normalize_last_layer': True,\n",
            "                        'num_crops': 2,\n",
            "                        'num_iters': 3,\n",
            "                        'num_prototypes': [3000],\n",
            "                        'output_dir': '',\n",
            "                        'queue': {'local_queue_length': 0,\n",
            "                                  'queue_length': 0,\n",
            "                                  'start_iter': 0},\n",
            "                        'temp_hard_assignment_iters': 0,\n",
            "                        'temperature': 0.1,\n",
            "                        'use_double_precision': False},\n",
            "          'swav_momentum_loss': {'crops_for_assign': [0, 1],\n",
            "                                 'embedding_dim': 128,\n",
            "                                 'epsilon': 0.05,\n",
            "                                 'momentum': 0.99,\n",
            "                                 'momentum_eval_mode_iter_start': 0,\n",
            "                                 'normalize_last_layer': True,\n",
            "                                 'num_crops': 2,\n",
            "                                 'num_iters': 3,\n",
            "                                 'num_prototypes': [3000],\n",
            "                                 'queue': {'local_queue_length': 0,\n",
            "                                           'queue_length': 0,\n",
            "                                           'start_iter': 0},\n",
            "                                 'temperature': 0.1,\n",
            "                                 'use_double_precision': False}},\n",
            " 'MACHINE': {'DEVICE': 'gpu'},\n",
            " 'METERS': {'accuracy_list_meter': {'meter_names': [],\n",
            "                                    'num_meters': 1,\n",
            "                                    'topk_values': [1]},\n",
            "            'enable_training_meter': True,\n",
            "            'mean_ap_list_meter': {'max_cpu_capacity': -1,\n",
            "                                   'meter_names': [],\n",
            "                                   'num_classes': 9605,\n",
            "                                   'num_meters': 1},\n",
            "            'name': ''},\n",
            " 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,\n",
            "                                        'USE_ACTIVATION_CHECKPOINTING': False},\n",
            "           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},\n",
            "                          'AMP_TYPE': 'apex',\n",
            "                          'USE_AMP': False},\n",
            "           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},\n",
            "           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,\n",
            "                                     'EVAL_TRUNK_AND_HEAD': False,\n",
            "                                     'EXTRACT_TRUNK_FEATURES_ONLY': True,\n",
            "                                     'FREEZE_TRUNK_AND_HEAD': False,\n",
            "                                     'FREEZE_TRUNK_ONLY': True,\n",
            "                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['conv1',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[10,\n",
            "                                                                           10],\n",
            "                                                                          10,\n",
            "                                                                          4]]],\n",
            "                                                                       ['res2',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[16,\n",
            "                                                                           16],\n",
            "                                                                          8,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res3',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[13,\n",
            "                                                                           13],\n",
            "                                                                          5,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res4',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[8,\n",
            "                                                                           8],\n",
            "                                                                          3,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res5',\n",
            "                                                                        ['AvgPool2d',\n",
            "                                                                         [[6,\n",
            "                                                                           6],\n",
            "                                                                          1,\n",
            "                                                                          0]]],\n",
            "                                                                       ['res5avg',\n",
            "                                                                        ['Identity',\n",
            "                                                                         []]]],\n",
            "                                     'SHOULD_FLATTEN_FEATS': False},\n",
            "           'HEAD': {'BATCHNORM_EPS': 1e-05,\n",
            "                    'BATCHNORM_MOMENTUM': 0.1,\n",
            "                    'PARAMS': [],\n",
            "                    'PARAMS_MULTIPLIER': 1.0},\n",
            "           'INPUT_TYPE': 'rgb',\n",
            "           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,\n",
            "                                'INPUT_SHAPE': [3, 224, 224]},\n",
            "           'MULTI_INPUT_HEAD_MAPPING': [],\n",
            "           'NON_TRAINABLE_PARAMS': [],\n",
            "           'SINGLE_PASS_EVERY_CROP': False,\n",
            "           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': False,\n",
            "                              'GROUP_SIZE': -1,\n",
            "                              'SYNC_BN_TYPE': 'pytorch'},\n",
            "           'TEMP_FROZEN_PARAMS_ITER_MAP': [],\n",
            "           'TRUNK': {'NAME': 'resnet',\n",
            "                     'TRUNK_PARAMS': {'EFFICIENT_NETS': {},\n",
            "                                      'REGNET': {},\n",
            "                                      'RESNETS': {'DEPTH': 50,\n",
            "                                                  'GROUPS': 1,\n",
            "                                                  'LAYER4_STRIDE': 2,\n",
            "                                                  'NORM': 'BatchNorm',\n",
            "                                                  'WIDTH_MULTIPLIER': 1,\n",
            "                                                  'WIDTH_PER_GROUP': 64,\n",
            "                                                  'ZERO_INIT_RESIDUAL': False}}},\n",
            "           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk.base_model._feature_blocks.',\n",
            "                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',\n",
            "                            'REMOVE_PREFIX': '',\n",
            "                            'SKIP_LAYERS': ['num_batches_tracked'],\n",
            "                            'STATE_DICT_KEY_NAME': ''}},\n",
            " 'MONITOR_PERF_STATS': False,\n",
            " 'MULTI_PROCESSING_METHOD': 'forkserver',\n",
            " 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},\n",
            " 'OPTIMIZER': {'head_optimizer_params': {'use_different_lr': False,\n",
            "                                         'use_different_wd': False,\n",
            "                                         'weight_decay': 0.0001},\n",
            "               'larc_config': {'clip': False,\n",
            "                               'eps': 1e-08,\n",
            "                               'trust_coefficient': 0.001},\n",
            "               'momentum': 0.9,\n",
            "               'name': 'sgd',\n",
            "               'nesterov': False,\n",
            "               'num_epochs': 90,\n",
            "               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                               'base_lr_batch_size': 256,\n",
            "                                                               'base_value': 0.1},\n",
            "                                           'end_value': 0.0,\n",
            "                                           'interval_scaling': [],\n",
            "                                           'lengths': [],\n",
            "                                           'milestones': [30, 60],\n",
            "                                           'name': 'multistep',\n",
            "                                           'schedulers': [],\n",
            "                                           'start_value': 0.1,\n",
            "                                           'update_interval': 'epoch',\n",
            "                                           'value': 0.1,\n",
            "                                           'values': [0.1, 0.01, 0.001]},\n",
            "                                    'lr_head': {'auto_lr_scaling': {'auto_scale': False,\n",
            "                                                                    'base_lr_batch_size': 256,\n",
            "                                                                    'base_value': 0.1},\n",
            "                                                'end_value': 0.0,\n",
            "                                                'interval_scaling': [],\n",
            "                                                'lengths': [],\n",
            "                                                'milestones': [30, 60],\n",
            "                                                'name': 'multistep',\n",
            "                                                'schedulers': [],\n",
            "                                                'start_value': 0.1,\n",
            "                                                'update_interval': 'epoch',\n",
            "                                                'value': 0.1,\n",
            "                                                'values': [0.1, 0.01, 0.001]}},\n",
            "               'regularize_bias': True,\n",
            "               'regularize_bn': False,\n",
            "               'use_larc': False,\n",
            "               'weight_decay': 0.0001},\n",
            " 'PERF_STAT_FREQUENCY': -1,\n",
            " 'ROLLING_BTIME_FREQ': -1,\n",
            " 'SEED_VALUE': 0,\n",
            " 'SVM': {'cls_list': [],\n",
            "         'costs': {'base': -1.0,\n",
            "                   'costs_list': [0.1, 0.01],\n",
            "                   'power_range': [4, 20]},\n",
            "         'cross_val_folds': 3,\n",
            "         'dual': True,\n",
            "         'force_retrain': False,\n",
            "         'loss': 'squared_hinge',\n",
            "         'low_shot': {'dataset_name': 'voc',\n",
            "                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],\n",
            "                      'sample_inds': [1, 2, 3, 4, 5]},\n",
            "         'max_iter': 2000,\n",
            "         'normalize': True,\n",
            "         'penalty': 'l2'},\n",
            " 'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',\n",
            "                       'FLUSH_EVERY_N_MIN': 5,\n",
            "                       'LOG_DIR': '.',\n",
            "                       'LOG_PARAMS': True,\n",
            "                       'LOG_PARAMS_EVERY_N_ITERS': 310,\n",
            "                       'LOG_PARAMS_GRADIENTS': True,\n",
            "                       'USE_TENSORBOARD': False},\n",
            " 'TEST_EVERY_NUM_EPOCH': 1,\n",
            " 'TEST_MODEL': True,\n",
            " 'TEST_ONLY': False,\n",
            " 'TRAINER': {'TASK_NAME': 'self_supervision_task',\n",
            "             'TRAIN_STEP_NAME': 'standard_train_step'},\n",
            " 'VERBOSE': False}\n",
            "INFO 2021-10-25 13:45:41,851 train.py:  89: System config:\n",
            "-------------------  ---------------------------------------------------------------\n",
            "sys.platform         linux\n",
            "Python               3.7.12 (default, Sep 10 2021, 00:21:48) [GCC 7.5.0]\n",
            "numpy                1.19.5\n",
            "Pillow               7.1.2\n",
            "vissl                0.1.5 @/usr/local/lib/python3.7/dist-packages/vissl\n",
            "GPU available        True\n",
            "GPU 0                Tesla K80\n",
            "CUDA_HOME            /usr/local/cuda\n",
            "torchvision          0.9.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "hydra                1.1.1 @/usr/local/lib/python3.7/dist-packages/hydra\n",
            "classy_vision        0.6.0.dev @/usr/local/lib/python3.7/dist-packages/classy_vision\n",
            "tensorboard          1.15.0\n",
            "apex                 0.1 @/usr/local/lib/python3.7/dist-packages/apex\n",
            "cv2                  4.1.2\n",
            "PyTorch              1.8.1+cu111 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build  False\n",
            "-------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.0.5\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "CPU info:\n",
            "-------------------  ------------------------------\n",
            "Architecture         x86_64\n",
            "CPU op-mode(s)       32-bit, 64-bit\n",
            "Byte Order           Little Endian\n",
            "CPU(s)               2\n",
            "On-line CPU(s) list  0,1\n",
            "Thread(s) per core   2\n",
            "Core(s) per socket   1\n",
            "Socket(s)            1\n",
            "NUMA node(s)         1\n",
            "Vendor ID            GenuineIntel\n",
            "CPU family           6\n",
            "Model                63\n",
            "Model name           Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping             0\n",
            "CPU MHz              2299.998\n",
            "BogoMIPS             4599.99\n",
            "Hypervisor vendor    KVM\n",
            "Virtualization type  full\n",
            "L1d cache            32K\n",
            "L1i cache            32K\n",
            "L2 cache             256K\n",
            "L3 cache             46080K\n",
            "NUMA node0 CPU(s)    0,1\n",
            "-------------------  ------------------------------\n",
            "INFO 2021-10-25 13:45:41,852 train_task.py: 192: Not using Automatic Mixed Precision\n",
            "INFO 2021-10-25 13:45:41,852 trainer_main.py: 109: Using Distributed init method: tcp://localhost:54433, world_size: 1, rank: 0\n",
            "INFO 2021-10-25 13:45:41,854 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "INFO 2021-10-25 13:45:41,854 trainer_main.py: 130: | initialized host 6ad74319c91f as rank 0 (0)\n",
            "INFO 2021-10-25 13:45:41,855 ssl_dataset.py: 130: Rank: 0 split: TEST Data files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-10-25 13:45:41,855 ssl_dataset.py: 133: Rank: 0 split: TEST Label files:\n",
            "['/content/dummy_data/val']\n",
            "INFO 2021-10-25 13:45:41,855 disk_dataset.py:  81: Loaded 10 samples from folder /content/dummy_data/val\n",
            "INFO 2021-10-25 13:45:41,856 ssl_dataset.py: 130: Rank: 0 split: TRAIN Data files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-10-25 13:45:41,856 ssl_dataset.py: 133: Rank: 0 split: TRAIN Label files:\n",
            "['/content/dummy_data/train']\n",
            "INFO 2021-10-25 13:45:41,856 disk_dataset.py:  81: Loaded 10 samples from folder /content/dummy_data/train\n",
            "INFO 2021-10-25 13:45:41,856 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-25 13:45:41,857 __init__.py:  91: Created the Distributed Sampler....\n",
            "INFO 2021-10-25 13:45:41,857 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "INFO 2021-10-25 13:45:41,857 __init__.py: 155: Wrapping the dataloader to async device copies\n",
            "INFO 2021-10-25 13:45:44,479 misc.py:  86: Set start method of multiprocessing to forkserver\n",
            "INFO 2021-10-25 13:45:44,479 __init__.py:  91: Created the Distributed Sampler....\n",
            "INFO 2021-10-25 13:45:44,479 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "INFO 2021-10-25 13:45:44,480 __init__.py: 155: Wrapping the dataloader to async device copies\n",
            "INFO 2021-10-25 13:45:44,480 train_task.py: 419: Building model....\n",
            "INFO 2021-10-25 13:45:44,481 feature_extractor.py:  23: Creating Feature extractor trunk...\n",
            "INFO 2021-10-25 13:45:44,481 resnext.py:  63: ResNeXT trunk, supports activation checkpointing. Deactivated\n",
            "INFO 2021-10-25 13:45:44,481 resnext.py:  83: Building model: ResNeXt50-1x64d-w1-BatchNorm2d\n",
            "INFO 2021-10-25 13:45:45,328 feature_extractor.py:  46: Freezing model trunk...\n",
            "INFO 2021-10-25 13:45:45,329 train_task.py: 437: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...\n",
            "INFO 2021-10-25 13:45:45,329 base_ssl_model.py: 181: Freezing model trunk...\n",
            "INFO 2021-10-25 13:45:45,330 train_task.py: 378: Initializing model from: /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-25 13:45:45,331 util.py: 277: Attempting to load checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-25 13:45:45,566 util.py: 282: Loaded checkpoint from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-25 13:45:45,566 util.py: 241: Broadcasting checkpoint loaded from /content/resnet50-19c8e357.pth\n",
            "INFO 2021-10-25 13:45:49,309 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,309 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,309 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,309 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,309 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,309 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,310 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,310 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,310 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,310 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,310 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,311 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,311 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,311 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,311 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,312 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,312 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,312 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,312 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,312 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,312 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,312 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,313 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,313 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,313 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,313 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,313 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,314 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,314 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,314 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,314 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,314 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,314 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,315 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,315 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,315 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,315 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,315 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,315 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,316 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,316 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,316 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,316 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,316 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,316 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,317 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,317 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,317 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,317 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,317 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,317 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,318 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,318 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,318 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,318 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,318 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,318 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,319 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,319 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,319 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,319 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,319 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,319 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,320 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,320 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,320 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer1.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,320 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,320 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,320 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,321 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,321 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,321 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,321 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,321 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,322 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,322 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,322 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,322 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,322 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,322 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,323 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,323 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,323 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,323 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,323 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,323 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,324 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,324 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,324 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,324 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,324 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,324 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,325 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,325 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,325 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,325 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,325 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,325 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,326 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,345 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,345 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,345 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,345 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,345 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,345 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,346 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,346 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,346 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,346 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,347 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,347 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,347 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,347 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,347 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,348 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,348 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,348 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,349 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,349 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,349 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,349 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,349 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,350 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,350 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,350 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,350 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,351 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,351 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,351 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,351 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,352 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,352 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,352 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,352 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,353 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,353 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,353 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,353 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,354 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,354 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,354 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,354 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,354 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,355 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer2.3.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,355 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,355 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,355 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,356 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,356 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,356 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,357 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,357 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,357 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,358 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,358 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,358 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,358 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,359 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,359 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,359 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,359 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,359 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,360 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,360 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,361 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,361 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,361 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,361 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,362 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,362 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,362 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,362 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,363 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,363 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,364 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,364 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,364 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,364 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,364 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,365 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,365 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,365 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,366 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,366 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,366 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,366 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,367 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,367 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,367 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,367 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,368 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,368 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,368 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,369 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,369 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,369 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,369 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,370 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,370 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,370 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,371 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,371 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,371 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,371 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,372 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,372 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,372 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,372 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,372 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,373 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,373 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,374 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,374 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,374 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,374 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,374 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,375 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,375 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,375 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,376 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,376 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,376 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.3.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,377 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,377 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,377 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,377 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,377 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,378 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,378 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,379 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,379 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,379 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,379 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,379 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,380 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,380 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,380 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,381 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,381 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,381 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.4.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,381 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,382 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,382 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,382 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,382 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,382 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,383 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,383 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,384 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,384 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,384 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,384 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,385 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,385 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,385 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,386 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,386 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,386 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer3.5.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,387 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,387 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,387 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,388 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,388 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,388 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,390 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,391 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,391 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,391 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,391 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,391 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,392 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,393 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,393 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,393 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,393 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,393 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,395 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,396 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,396 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,396 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,396 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,396 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,397 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,397 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,398 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,398 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,398 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,398 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,400 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,400 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,401 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,401 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,401 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,401 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,402 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,402 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,403 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,403 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,403 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,403 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.1.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,404 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,404 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,404 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,405 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,405 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,405 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn1.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,407 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,407 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,407 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,408 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,408 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,408 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn2.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,409 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,409 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,409 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,410 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,410 checkpoint.py: 455: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint\n",
            "INFO 2021-10-25 13:45:49,410 checkpoint.py: 427: Ignored layer:\ttrunk.base_model._feature_blocks.layer4.2.bn3.num_batches_tracked\n",
            "INFO 2021-10-25 13:45:49,410 checkpoint.py: 470: Extra layers not loaded from checkpoint: ['trunk.base_model._feature_blocks.fc.weight', 'trunk.base_model._feature_blocks.fc.bias']\n",
            "INFO 2021-10-25 13:45:49,413 train_task.py: 591: Broadcast model BN buffers from master on every forward pass\n",
            "INFO 2021-10-25 13:45:49,413 classification_task.py: 359: Synchronized Batch Normalization is disabled\n",
            "INFO 2021-10-25 13:45:49,413 train_task.py: 340: Building loss...\n",
            "INFO 2021-10-25 13:45:49,472 optimizer_helper.py: 157: \n",
            "Trainable params: 0, \n",
            "Non-Trainable params: 0, \n",
            "Trunk Regularized Parameters: 0, \n",
            "Trunk Unregularized Parameters 0, \n",
            "Head Regularized Parameters: 0, \n",
            "Head Unregularized Parameters: 0 \n",
            "Remaining Regularized Parameters: 0 \n",
            "INFO 2021-10-25 13:45:49,473 trainer_main.py: 241: Training 90 epochs. One epoch = 5 iterations\n",
            "INFO 2021-10-25 13:45:49,473 trainer_main.py: 243: Total 450 iterations for training\n",
            "INFO 2021-10-25 13:45:49,473 trainer_main.py: 244: Total 10 samples in one epoch\n",
            "INFO 2021-10-25 13:45:49,622 logger.py:  76: Mon Oct 25 13:45:49 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    74W / 149W |    600MiB / 11441MiB |      8%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "INFO 2021-10-25 13:45:49,624 trainer_main.py: 166: Model is:\n",
            " Classy <class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'>:\n",
            "BaseSSLMultiInputOutputModel(\n",
            "  (_heads): ModuleDict()\n",
            "  (trunk): FeatureExtractorModel(\n",
            "    (base_model): ResNeXt(\n",
            "      (_feature_blocks): ModuleDict(\n",
            "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv1_relu): ReLU(inplace=True)\n",
            "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer2): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer3): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (5): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (layer4): Sequential(\n",
            "          (0): Bottleneck(\n",
            "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(<SUPPORTED_L4_STRIDE.two: 2>, <SUPPORTED_L4_STRIDE.two: 2>), bias=False)\n",
            "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): Bottleneck(\n",
            "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (flatten): Flatten()\n",
            "      )\n",
            "    )\n",
            "    (feature_pool_ops): ModuleList(\n",
            "      (0): AvgPool2d(kernel_size=[10, 10], stride=10, padding=4)\n",
            "      (1): AvgPool2d(kernel_size=[16, 16], stride=8, padding=0)\n",
            "      (2): AvgPool2d(kernel_size=[13, 13], stride=5, padding=0)\n",
            "      (3): AvgPool2d(kernel_size=[8, 8], stride=3, padding=0)\n",
            "      (4): AvgPool2d(kernel_size=[6, 6], stride=1, padding=0)\n",
            "      (5): Identity()\n",
            "    )\n",
            "  )\n",
            "  (heads): ModuleList()\n",
            ")\n",
            "INFO 2021-10-25 13:45:49,695 trainer_main.py: 167: Loss is: CrossEntropyLoss()\n",
            "INFO 2021-10-25 13:45:49,696 trainer_main.py: 168: Starting training....\n",
            "INFO 2021-10-25 13:45:49,696 __init__.py:  72: Distributed Sampler config:\n",
            "{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Traceback (most recent call last):\n",
            "  File \"run_distributed_engines.py\", line 194, in <module>\n",
            "    hydra_main(overrides=overrides)\n",
            "  File \"run_distributed_engines.py\", line 179, in hydra_main\n",
            "    hook_generator=default_hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 123, in launch_distributed\n",
            "    hook_generator=hook_generator,\n",
            "  File \"run_distributed_engines.py\", line 166, in _distributed_worker\n",
            "    process_main(cfg, dist_run_id, local_rank=local_rank, node_id=node_id)\n",
            "  File \"run_distributed_engines.py\", line 159, in process_main\n",
            "    hook_generator=hook_generator,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/vissl/engines/train.py\", line 102, in train_main\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/vissl/trainer/trainer_main.py\", line 171, in train\n",
            "    self._advance_phase(task)  # advances task.phase_idx\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/vissl/trainer/trainer_main.py\", line 286, in _advance_phase\n",
            "    phase_type, epoch=task.phase_idx, compute_start_iter=compute_start_iter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/vissl/trainer/train_task.py\", line 501, in recreate_data_iterator\n",
            "    self.data_iterator = iter(self.dataloaders[phase_type])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/classy_vision/dataset/dataloader_async_gpu_wrapper.py\", line 40, in __iter__\n",
            "    self.preload()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/classy_vision/dataset/dataloader_async_gpu_wrapper.py\", line 46, in preload\n",
            "    self.cache_next = next(self._iter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1199, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1225, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 429, in reraise\n",
            "    raise self.exc_type(msg)\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n",
            "    return self.collate_fn(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 73, in default_collate\n",
            "    return {key: default_collate([d[key] for d in batch]) for key in elem}\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 73, in <dictcomp>\n",
            "    return {key: default_collate([d[key] for d in batch]) for key in elem}\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n",
            "    return [default_collate(samples) for samples in transposed]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n",
            "    return [default_collate(samples) for samples in transposed]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 85, in default_collate\n",
            "    raise TypeError(default_collate_err_msg_format.format(elem_type))\n",
            "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8fILq7VzyOu"
      },
      "source": [
        "And we are done!! We have the features for layers `conv1, res2, res3, res4, res5, res5avg` in `checkpoints/*.npy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otUmgl4ms96M",
        "outputId": "169f2b71-5d75-4f5d-a3e7-a6f0a87f3e6b"
      },
      "source": [
        "ls checkpoints/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xFUcTj00B_a"
      },
      "source": [
        "# Loading Pre-trained models in VISSL\n",
        "\n",
        "VISSL supports Torchvision models out of the box. Generally, for loading any non-VISSL model, one needs to correctly set the following configuration options:\n",
        "\n",
        "```yaml\n",
        "WEIGHTS_INIT:\n",
        "  # path to the .torch weights files\n",
        "  PARAMS_FILE: \"\"\n",
        "  # name of the state dict. checkpoint = {\"classy_state_dict\": {layername:value}}. Options:\n",
        "  #   1. classy_state_dict - if model is trained and checkpointed with VISSL.\n",
        "  #      checkpoint = {\"classy_state_dict\": {layername:value}}\n",
        "  #   2. \"\" - if the model_file is not a nested dictionary for model weights i.e.\n",
        "  #      checkpoint = {layername:value}\n",
        "  #   3. key name that your model checkpoint uses for state_dict key name.\n",
        "  #      checkpoint = {\"your_key_name\": {layername:value}}\n",
        "  STATE_DICT_KEY_NAME: \"classy_state_dict\"\n",
        "  # specify what layer should not be loaded. Layer names with this key are not copied\n",
        "  # By default, set to BatchNorm stats \"num_batches_tracked\" to be skipped.\n",
        "  SKIP_LAYERS: [\"num_batches_tracked\"]\n",
        "  ####### If loading a non-VISSL trained model, set the following two args carefully #########\n",
        "  # to make the checkpoint compatible with VISSL, if you need to remove some names\n",
        "  # from the checkpoint keys, specify the name\n",
        "  REMOVE_PREFIX: \"\"\n",
        "  # In order to load the model (if not trained with VISSL) with VISSL, there are 2 scenarios:\n",
        "  #    1. If you are interested in evaluating the model features and freeze the trunk.\n",
        "  #       Set APPEND_PREFIX=\"trunk.base_model.\" This assumes that your model is compatible\n",
        "  #       with the VISSL trunks. The VISSL trunks start with \"_feature_blocks.\" prefix. If\n",
        "  #       your model doesn't have these prefix you can append them. For example:\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk.base_model._feature_blocks.\"\n",
        "  #    2. where you want to load the model simply and finetune the full model.\n",
        "  #       Set APPEND_PREFIX=\"trunk.\"\n",
        "  #       This assumes that your model is compatible with the VISSL trunks. The VISSL\n",
        "  #       trunks start with \"_feature_blocks.\" prefix. If your model doesn't have these\n",
        "  #       prefix you can append them.\n",
        "  #       For TorchVision ResNet trunk, set APPEND_PREFIX=\"trunk._feature_blocks.\"\n",
        "  # NOTE: the prefix is appended to all the layers in the model\n",
        "  APPEND_PREFIX: \"\"\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc9YxGbNtFg6"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}